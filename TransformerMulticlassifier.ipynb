{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerMulticlassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bL5ZsuZcnYTLlfxEFH2nopN-kofTOBzy",
      "authorship_tag": "ABX9TyMJfd8Yc8iIqAFjDTl9ybOA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ecb07b3b635476e86b1ca296f5bc41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_989feed7af0f4a469553b84c1c606ae3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa662a8495354c3c8a0290447f2eee48",
              "IPY_MODEL_e1b265b59c814ebc9aa4992b43f8e603",
              "IPY_MODEL_344dae7f6a2c440ba1043264948a090f"
            ]
          }
        },
        "989feed7af0f4a469553b84c1c606ae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa662a8495354c3c8a0290447f2eee48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f651857430a145dfa414ab3c0b774714",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a7a0676c651477a8edc8304abcf1312"
          }
        },
        "e1b265b59c814ebc9aa4992b43f8e603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f1e0fedac72b461bad2f54d9a610a6c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd33663e20c04621be8731daf1d537fa"
          }
        },
        "344dae7f6a2c440ba1043264948a090f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_551b833d9ab44017b443baf2fa6e50ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 17.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aed2f1a86abb428e9550cf693cadebfd"
          }
        },
        "f651857430a145dfa414ab3c0b774714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a7a0676c651477a8edc8304abcf1312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1e0fedac72b461bad2f54d9a610a6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd33663e20c04621be8731daf1d537fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "551b833d9ab44017b443baf2fa6e50ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aed2f1a86abb428e9550cf693cadebfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03a95ab4b2e64250824ffa8510f6323d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_833dba4917704e88ba41f9b66323b3a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_02b81d00661a40aebff48bc820fb3ed3",
              "IPY_MODEL_966743bec1514cc09d021e613ae9690f",
              "IPY_MODEL_1dadf827bc9149bcb951a41d956d8fc3"
            ]
          }
        },
        "833dba4917704e88ba41f9b66323b3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02b81d00661a40aebff48bc820fb3ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a262501bec04a4eb387392c74d7ab19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8e9bc00230d4d34afa5effb3245656f"
          }
        },
        "966743bec1514cc09d021e613ae9690f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1b5ea6b7e5114c7ba8d825f478ba2935",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d79f90f4d594e08a2c3c99689e5bbea"
          }
        },
        "1dadf827bc9149bcb951a41d956d8fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85b184f80a80470ca6ded6f3020be01b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:08&lt;00:00, 55.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9003d7e7f7cf487c81412e99dfbd637c"
          }
        },
        "8a262501bec04a4eb387392c74d7ab19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8e9bc00230d4d34afa5effb3245656f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b5ea6b7e5114c7ba8d825f478ba2935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d79f90f4d594e08a2c3c99689e5bbea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85b184f80a80470ca6ded6f3020be01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9003d7e7f7cf487c81412e99dfbd637c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pimverschuuren/ComplaintDepartment/blob/main/TransformerMulticlassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkL5A_Uda1Wp"
      },
      "source": [
        "Get the dataset in compressed form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQPqpnByll2n",
        "outputId": "16f01dd0-a12e-4a41-f54b-1c3d98f33c9c"
      },
      "source": [
        "!wget https://files.consumerfinance.gov/ccdb/complaints.csv.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-27 16:25:11--  https://files.consumerfinance.gov/ccdb/complaints.csv.zip\n",
            "Resolving files.consumerfinance.gov (files.consumerfinance.gov)... 52.84.158.12, 52.84.158.8, 52.84.158.48, ...\n",
            "Connecting to files.consumerfinance.gov (files.consumerfinance.gov)|52.84.158.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 383843806 (366M) [binary/octet-stream]\n",
            "Saving to: ‘complaints.csv.zip’\n",
            "\n",
            "complaints.csv.zip  100%[===================>] 366.06M   123MB/s    in 3.0s    \n",
            "\n",
            "2021-10-27 16:25:14 (123 MB/s) - ‘complaints.csv.zip’ saved [383843806/383843806]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNi4OveQl-jr"
      },
      "source": [
        "Decompress the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUBUS1dPmBbT",
        "outputId": "ead5fdf7-1889-4a3c-9587-445674c6c0df"
      },
      "source": [
        "!unzip complaints.csv.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  complaints.csv.zip\n",
            "  inflating: complaints.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFZsNheSTOnm"
      },
      "source": [
        "Setting up GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-oerT9kTQUx"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDS4x9wPmTFS"
      },
      "source": [
        "Install and import some libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPFPu023mqAY",
        "outputId": "9f6ec21a-d7f5-44cb-d59c-b9c4efb3530c"
      },
      "source": [
        "# Install the transformers package of Hugging Face.\n",
        "!pip install transformers\n",
        "\n",
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "from transformers import BertModel, BertTokenizer\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 7.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 64.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARiqUTB9ms7S"
      },
      "source": [
        "Load the dataset into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMt6EUbIm64w"
      },
      "source": [
        "total_dataset_full = pd.read_csv('complaints.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCJS1XNgnJ_6"
      },
      "source": [
        "Possible prediction variables: Company public response and product.\n",
        "\n",
        "Future use of the predictions: In case of company public responses, it is hard for a human being to choose the optimal public response to a complaint from 10 categories. Predicting a public response based on the complaint would be a helpful tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR_VNPHPCQnD"
      },
      "source": [
        "Lets pre-process the data by removing nan values from the target variable and complaints. Also, when printing the frequency if each class in the target variable we see a large class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwq3iB4CFUuk",
        "outputId": "b2f722f2-00aa-4a5b-b7ef-09e32d2841e9"
      },
      "source": [
        "text_variable = 'Consumer complaint narrative'\n",
        "target_variable = 'Company public response'\n",
        "\n",
        "print(\"Total number of statistics: \"+str(len(total_dataset_full)))\n",
        "\n",
        "total_dataset_full = total_dataset_full.dropna(subset=[text_variable])\n",
        "total_dataset_full = total_dataset_full.dropna(subset=[target_variable])\n",
        "\n",
        "print(\"Remaining number of statistics: \"+str(len(total_dataset_full)))\n",
        "print(\"Number of remaining classes are: \"+str(total_dataset_full[target_variable].nunique()))\n",
        "total_dataset_full[target_variable].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of statistics: 2317009\n",
            "Remaining number of statistics: 391199\n",
            "Number of remaining classes are: 11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Company has responded to the consumer and the CFPB and chooses not to provide a public response                            306269\n",
              "Company believes it acted appropriately as authorized by contract or law                                                    46119\n",
              "Company chooses not to provide a public response                                                                            19818\n",
              "Company believes the complaint is the result of a misunderstanding                                                           4643\n",
              "Company disputes the facts presented in the complaint                                                                        4251\n",
              "Company believes complaint is the result of an isolated error                                                                2811\n",
              "Company believes complaint caused principally by actions of third party outside the control or direction of the company      2759\n",
              "Company believes complaint represents an opportunity for improvement to better serve consumers                               2140\n",
              "Company can't verify or dispute the facts in the complaint                                                                   1554\n",
              "Company believes the complaint provided an opportunity to answer consumer's questions                                         784\n",
              "Company believes complaint relates to a discontinued policy or procedure                                                       51\n",
              "Name: Company public response, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5N3esAM8knH"
      },
      "source": [
        "Here we resample the classes to balance the dataset in its target variable. This is to avoid the model learns to predict only the class that occurs the most in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-THa3g77Rub",
        "outputId": "e27b8c2e-c34d-414f-c358-a213775ee195"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "total_dataset = None\n",
        "\n",
        "# Define the number of occurences wanted for each class. 1000 is realitively low\n",
        "max_len = 5000\n",
        "\n",
        "for index, class_val in enumerate(total_dataset_full[target_variable].unique()):\n",
        "\n",
        "  class_dataset = total_dataset_full.loc[total_dataset_full[target_variable] == class_val]\n",
        "\n",
        "  class_dataset = resample(class_dataset,\n",
        "                                 replace=True,\n",
        "                                 n_samples=max_len,\n",
        "                                 random_state=42)\n",
        "\n",
        "  if index == 0:\n",
        "    total_dataset = class_dataset.copy()\n",
        "  else:\n",
        "    total_dataset = pd.concat([total_dataset, class_dataset])\n",
        "\n",
        "print(total_dataset[target_variable].value_counts())\n",
        "\n",
        "# Include this line if a smaller dataset is needed for debugging.\n",
        "#total_dataset = total_dataset_full.sample(frac=0.0005)\n",
        "\n",
        "#print(total_dataset[target_variable].value_counts())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company has responded to the consumer and the CFPB and chooses not to provide a public response                            5000\n",
            "Company believes complaint caused principally by actions of third party outside the control or direction of the company    5000\n",
            "Company believes complaint represents an opportunity for improvement to better serve consumers                             5000\n",
            "Company chooses not to provide a public response                                                                           5000\n",
            "Company can't verify or dispute the facts in the complaint                                                                 5000\n",
            "Company believes complaint is the result of an isolated error                                                              5000\n",
            "Company believes it acted appropriately as authorized by contract or law                                                   5000\n",
            "Company believes the complaint is the result of a misunderstanding                                                         5000\n",
            "Company believes complaint relates to a discontinued policy or procedure                                                   5000\n",
            "Company disputes the facts presented in the complaint                                                                      5000\n",
            "Company believes the complaint provided an opportunity to answer consumer's questions                                      5000\n",
            "Name: Company public response, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve-HKM3nK7El"
      },
      "source": [
        "Make a loading object that will pass tokenize and pass the data to the dataloader to avoid loading all the data in memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyaE8Dp7IMrA"
      },
      "source": [
        "encode_dict = {}\n",
        "\n",
        "def encode_product(x):\n",
        "    if x not in encode_dict.keys():\n",
        "        encode_dict[x]=len(encode_dict)\n",
        "    return encode_dict[x]\n",
        "\n",
        "class dataset_fold_BERT(Dataset):\n",
        "    def __init__(self, xfold, yfold, tokenizer, max_len):\n",
        "        self.len = len(xfold)\n",
        "        self.xfold = xfold\n",
        "        self.yfold = yfold\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        sentence = str(self.xfold.iloc[index][text_variable])\n",
        "        #title = \" \".join(title.split())\n",
        "        #print(sentence)\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'targets': self.yfold[index]\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxf30BhKgluf"
      },
      "source": [
        "Make a dataloader for k folds with stratified target variable classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4Jeu9gLOUFr"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Define the number of folds.\n",
        "k = 5\n",
        "\n",
        "# Get the number of categories for the target variable.\n",
        "n_class = total_dataset[target_variable].nunique()\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=(k))\n",
        "\n",
        "# Define a maximum length for the complaint to be truncated to.\n",
        "max_len = 512\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 4\n",
        "\n",
        "# Number of training epochs.\n",
        "epochs = 1\n",
        "\n",
        "# Learning rate for the optimizer.\n",
        "lr = 1e-05\n",
        "\n",
        "# Tokenizer to convert the text into tokens.\n",
        "#tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "predictors = total_dataset.drop(target_variable, axis=1)\n",
        "\n",
        "# Convert the products to integers.\n",
        "target = total_dataset[target_variable].apply(lambda x: encode_product(x))\n",
        "\n",
        "# Create a dict that will contain the dataloaders for all folds.\n",
        "all_dataloaders = {}\n",
        "\n",
        "# Define the dataloader parameters.\n",
        "train_params = {'batch_size': batch_size,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "fold_count = 1\n",
        "\n",
        "# Loop over the folds.\n",
        "for _, fold in kfold.split(predictors, target):\n",
        "\n",
        "    fold_name = \"fold_\"+str(fold_count)\n",
        "    fold_count = fold_count + 1\n",
        "\n",
        "    # Only keep the text variable column.\n",
        "    X_fold = predictors.iloc[fold]\n",
        "    y_fold = target.iloc[fold]\n",
        "\n",
        "    # Convert to tensor.\n",
        "    y_fold = torch.tensor(y_fold.values.astype(np.int64))\n",
        "\n",
        "    # Get the dataset fold.\n",
        "    training_fold = dataset_fold_BERT(X_fold, y_fold, tokenizer, max_len)\n",
        "\n",
        "    # Get the dataloader.\n",
        "    dataloader_fold = DataLoader(training_fold, **train_params)\n",
        "\n",
        "    # Put all the dataloaders in a dict.\n",
        "    all_dataloaders[fold_name] = dataloader_fold"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMNJZvKGLBLv"
      },
      "source": [
        "Define two different models. Both use the pretrained BERT model as first layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dyX80ocXPhp"
      },
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self, n_class, hidden_dim, dropout):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        #self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, hidden_dim)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.classifier = torch.nn.Linear(hidden_dim, n_class)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output\n",
        "\n",
        "class GRUBERTClass(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        \n",
        "        embedding_dim = self.bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.rnn = torch.nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.out = torch.nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, text):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          embedded = self.bert(text)[0]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        return output\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYkTSG29hgrP"
      },
      "source": [
        "Instantiate the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc6bUcX0XTLP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4ecb07b3b635476e86b1ca296f5bc41b",
            "989feed7af0f4a469553b84c1c606ae3",
            "aa662a8495354c3c8a0290447f2eee48",
            "e1b265b59c814ebc9aa4992b43f8e603",
            "344dae7f6a2c440ba1043264948a090f",
            "f651857430a145dfa414ab3c0b774714",
            "9a7a0676c651477a8edc8304abcf1312",
            "f1e0fedac72b461bad2f54d9a610a6c2",
            "fd33663e20c04621be8731daf1d537fa",
            "551b833d9ab44017b443baf2fa6e50ba",
            "aed2f1a86abb428e9550cf693cadebfd",
            "03a95ab4b2e64250824ffa8510f6323d",
            "833dba4917704e88ba41f9b66323b3a8",
            "02b81d00661a40aebff48bc820fb3ed3",
            "966743bec1514cc09d021e613ae9690f",
            "1dadf827bc9149bcb951a41d956d8fc3",
            "8a262501bec04a4eb387392c74d7ab19",
            "d8e9bc00230d4d34afa5effb3245656f",
            "1b5ea6b7e5114c7ba8d825f478ba2935",
            "5d79f90f4d594e08a2c3c99689e5bbea",
            "85b184f80a80470ca6ded6f3020be01b",
            "9003d7e7f7cf487c81412e99dfbd637c"
          ]
        },
        "outputId": "0b161ea9-7b20-424e-8f32-7f06da8be10c"
      },
      "source": [
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "bidirectional = False\n",
        "dropout = 0.2\n",
        "\n",
        "model = BERTClass(n_class, hidden_dim, dropout)\n",
        "'''\n",
        "model = GRUBERTClass(hidden_dim,\n",
        "                 n_class,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout)\n",
        "'''\n",
        "model.to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ecb07b3b635476e86b1ca296f5bc41b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03a95ab4b2e64250824ffa8510f6323d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=256, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (classifier): Linear(in_features=256, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL6Q4nVena4I"
      },
      "source": [
        "Define a function that gives the number of learnable parameters. This gives an indication of the model complexity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh7kE4AAneQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb53189-5ae4-4d0d-b60f-a9e7354b3060"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "count_parameters(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 109,681,931 trainable parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109681931"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csxpbiXWXW9R"
      },
      "source": [
        "# Creating the loss function and optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=lr)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0AwJb8ZZEj0"
      },
      "source": [
        "Define functions to calculate the accuracy, recall and precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZUnx-PMZF4f"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "def calculate_accu(big_idx, targets):\n",
        "# Calculate the accuracy for a multiclass prediction.\n",
        "    n_correct = (big_idx==targets).sum().item()\n",
        "    return n_correct\n",
        "\n",
        "def averaged_recall_precision(confusion_matrix):\n",
        "    \n",
        "    sum_precision = 0\n",
        "    sum_recall = 0\n",
        "\n",
        "    # Sum along row/col.\n",
        "    sum_rows = np.sum(confusion_matrix, axis=0)\n",
        "    sum_cols = np.sum(confusion_matrix, axis=1)\n",
        "\n",
        "    # Sum all the precisions.\n",
        "    for i_class in range(confusion_matrix.shape[0]):\n",
        "      sum_precision += confusion_matrix[i_class,i_class]/sum_rows[i_class]\n",
        "      \n",
        "    \n",
        "    # Sum all recalls.\n",
        "    for i_class in range(confusion_matrix.shape[0]):\n",
        "      sum_recall += confusion_matrix[i_class,i_class]/sum_cols[i_class]\n",
        "\n",
        "    return sum_recall/confusion_matrix.shape[0], sum_precision/confusion_matrix.shape[0]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyVIj95uNwD2"
      },
      "source": [
        "Define a function that can calculate the passed time for during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLRZ-RMeNyVJ"
      },
      "source": [
        "def passed_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Z9QaATxcO9"
      },
      "source": [
        "Save the untrained model so that for each fold the model can be trained from its initial state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeehfgB4xfuG"
      },
      "source": [
        "torch.save(model.state_dict(), 'initial_state.pt')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsW5M-8tXir-"
      },
      "source": [
        "Define the training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uH_LOetXkq9"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def cv_training(n_epochs, n_steps_per_print):\n",
        "\n",
        "    final_precision = 0\n",
        "    final_recall = 0\n",
        "    final_f1 = 0\n",
        "    final_acc = 0\n",
        "\n",
        "    for fold_val_key in all_dataloaders:\n",
        "\n",
        "      # Initiate the initial state of the model for each fold.\n",
        "      model.load_state_dict(torch.load('initial_state.pt')) \n",
        "\n",
        "      # Reset everything for validation fold.\n",
        "      tr_loss = 0\n",
        "      n_tr_correct = 0\n",
        "      n_val_correct = 0\n",
        "      confusion_matrix_train = np.zeros((n_class, n_class))\n",
        "      confusion_matrix_val = np.zeros((n_class, n_class))\n",
        "\n",
        "      nb_tr_steps = 0\n",
        "      nb_tr_examples = 0\n",
        "\n",
        "      nb_val_examples = 0\n",
        "\n",
        "      model.train()\n",
        "      time_a = time.time()\n",
        "\n",
        "      for fold_train_key in all_dataloaders:\n",
        "        \n",
        "        if fold_train_key == fold_val_key:\n",
        "          continue\n",
        "\n",
        "        print(\"Training on \"+fold_train_key)\n",
        "\n",
        "        # Perform training.\n",
        "        for epoch in range(n_epochs): \n",
        "\n",
        "          print(f\"Epoch {epoch}\")\n",
        "\n",
        "          for _,data in enumerate(all_dataloaders[fold_train_key], 0):\n",
        "              \n",
        "              # Get tokenized input text.\n",
        "              ids = data['ids'].to(device, dtype = torch.long)\n",
        "              mask = data['mask'].to(device, dtype = torch.long)\n",
        "              \n",
        "              # Get the target variable.\n",
        "              targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "              # If using BERT Classifier, also pass masks.\n",
        "              outputs = model(ids, mask)\n",
        "\n",
        "              # If using GRU Classiifier, only pass tokens.\n",
        "              #outputs = model(ids)\n",
        "\n",
        "              # Get the loss function.\n",
        "              loss = loss_function(outputs, targets)\n",
        "\n",
        "              # Sum the loss\n",
        "              tr_loss += loss.item()\n",
        "\n",
        "              # Get class that had the highest classifier output i.e. the class\n",
        "              # that the model predicts.\n",
        "              big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "\n",
        "              # Update the confusion matrix.\n",
        "              for i in range(len(big_idx)):\n",
        "                confusion_matrix_train[big_idx[i],targets[i]] += 1\n",
        "\n",
        "              # Get the number of correct classifications for the whole batch.\n",
        "              n_tr_correct += calculate_accu(big_idx, targets)\n",
        "\n",
        "              nb_tr_steps += 1\n",
        "              nb_tr_examples+=targets.size(0)\n",
        "              \n",
        "              if _%n_steps_per_print==0:\n",
        "                  mins, secs = passed_time(time_a, time.time())\n",
        "                  print(f'Passed Time: {mins}m {secs}s')\n",
        "\n",
        "                  loss_step = tr_loss/nb_tr_steps\n",
        "                  acc = (n_tr_correct*100)/nb_tr_examples\n",
        "                  av_recall, av_precision = averaged_recall_precision(confusion_matrix_train)\n",
        "                  f1_score = 2*av_recall*av_precision/(av_recall + av_precision)\n",
        "\n",
        "                  print(\"==================================\")\n",
        "                  print(\"After \"+str(nb_tr_steps)+\" steps:\")\n",
        "                  print(f\"Training Loss: {loss_step}\")\n",
        "                  print(f\"Training Av. Recall: {av_recall}\")\n",
        "                  print(f\"Training Av. Precision: {av_precision}\")\n",
        "                  print(f\"Training F1-score: {f1_score}\")\n",
        "                  print(f\"Training Accuracy: {acc}\")\n",
        "                  print(\"==================================\")\n",
        "\n",
        "                  time_a = time.time()\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "              loss.backward()\n",
        "              # # When using GPU\n",
        "              optimizer.step()\n",
        "              \n",
        "      # Turns of dropout.\n",
        "      model.eval()\n",
        "\n",
        "      # Fix the parameters.\n",
        "      with torch.no_grad():\n",
        "        \n",
        "        for index,data in enumerate(all_dataloaders[fold_val_key], 0):\n",
        "\n",
        "          # Get tokenized input text.\n",
        "          ids = data['ids'].to(device, dtype = torch.long)\n",
        "          mask = data['mask'].to(device, dtype = torch.long)\n",
        "\n",
        "          # Get the target variable.\n",
        "          targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "          # If using BERT Classifier, also pass masks.\n",
        "          outputs = model(ids, mask)\n",
        "          \n",
        "          # If using GRU Classiifier, only pass tokens.\n",
        "          #outputs = model(ids)\n",
        "\n",
        "          # Get class that had the highest classifier output i.e. the class\n",
        "          # that the model predicts.\n",
        "          big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "\n",
        "          # Get the number of correct classifications for the whole batch.\n",
        "          n_val_correct += calculate_accu(big_idx, targets)\n",
        "\n",
        "          # Update the confusion matrix.\n",
        "          for i in range(len(big_idx)):\n",
        "            confusion_matrix_val[big_idx[i],targets[i]] += 1\n",
        "\n",
        "          nb_val_examples+=targets.size(0)\n",
        "\n",
        "        acc = (n_val_correct*100)/nb_val_examples\n",
        "        av_recall, av_precision = averaged_recall_precision(confusion_matrix_val)\n",
        "        f1_score = 2*av_recall*av_precision/(av_recall + av_precision)\n",
        "\n",
        "        print(\"============= Validation of \"+fold_val_key+\"=============\")\n",
        "        print(f\"Val. Accuracy: {acc}\")\n",
        "        print(f\"Val. Av. recall: {av_recall}\")\n",
        "        print(f\"Val. Av. precision: {av_precision}\")\n",
        "        print(f\"Val. F1-score: {f1_score}\")\n",
        "        print(\"==================================\")\n",
        "        \n",
        "        final_acc += acc\n",
        "        final_recall += av_recall\n",
        "        final_precision += av_precision\n",
        "        final_f1 += f1_score\n",
        "\n",
        "    final_acc = final_acc/k\n",
        "    final_recall = final_recall/k\n",
        "    final_precision = final_precision/k\n",
        "    final_f1 = final_f1/k\n",
        "\n",
        "    print(\"============= All folds averages =============\")\n",
        "    print(f\"Val. Accuracy: {final_acc}\")\n",
        "    print(f\"Val. Av. recall: {final_recall}\")\n",
        "    print(f\"Val. Av. precision: {final_precision}\")\n",
        "    print(f\"Val. F1-score: {final_f1}\")\n",
        "    \n",
        "    return "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL4VmdvAmsdy"
      },
      "source": [
        "cv_training(1,1000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}